{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the environment has been set up, this notebook should be able to be run, cell-by-cell. One issue is that I've made modifications to k-wave-python (to cache and re-use gridweights, which saves a significant amount of time if you are running different simulations using the same array in the same position - it's being discussed in https://github.com/waltsims/k-wave-python/issues/342, but hasn't been merged yet, afaik). \n",
    "\n",
    "If you have my modified version of k-wave-python, install it with `pip install -e .` from the `k-wave-python` directory. If you don't have my modified version, you can install the original version with `pip install k-wave-python`. If you are using the original version, be sure to set `USE_GRIDWEIGHTS` to `False` in order to prevent `open_pyfus` from trying to use a nonexistent interface for loading the gridweights. \n",
    "\n",
    "Also, if you are using the original version, import `openlifu` takes _way_ longer (45s on my PC), presumably hanging on `import kwave`. For some reason, it wants to re-download the binaries every time, even though they are already present in the the installation directory. I've opened an issue on this: https://github.com/waltsims/k-wave-python/issues/366."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import logging\n",
    "root = logging.getLogger()\n",
    "loglevel = logging.DEBUG\n",
    "root.setLevel(loglevel)\n",
    "handler = logging.StreamHandler(sys.stdout)\n",
    "handler.setLevel(loglevel)\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "root.addHandler(handler)\n",
    "import openlifu\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by generating a transducer and drawing it using some vtk-based methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = openlifu.Transducer.gen_matrix_array(nx=8, ny=8, pitch=4, kerf=.5, units=\"mm\", impulse_response=1e5)\n",
    "arr.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll define the pulse and sequence parameters, the simulation setup, and generate a Protocol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pulse = openlifu.Pulse(frequency=400e3, duration=3/400e3)\n",
    "sequence = openlifu.Sequence()\n",
    "focal_pattern = openlifu.focal_patterns.Wheel(center=True, spoke_radius=5, num_spokes=5)\n",
    "sim_setup = openlifu.SimSetup(dt=2e-7, t_end=100e-6)\n",
    "protocol = openlifu.Protocol(\n",
    "    pulse=pulse,\n",
    "    sequence=sequence,\n",
    "    focal_pattern=focal_pattern,\n",
    "    sim_setup=sim_setup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can define a sonication target(s), set up the simulation, and compute the delays and apodizations needed to steer the sound to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt = openlifu.Point(position=(0,0,30), units=\"mm\", radius=2)\n",
    "pts = protocol.focal_pattern.get_targets(pt)\n",
    "coords = protocol.sim_setup.get_coords()\n",
    "params = protocol.seg_method.ref_params(coords)\n",
    "delays, apod = protocol.beamform(arr=arr, target=pts[0], params=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to run the simulation.  Some custom edits to `k-wave-python` allow for caching of the gridweights, which only need to be computed once for a given grid size and source location.  This can speed up the simulation significantly, especially if a coarse grid that won't take the GPU too long to run is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ds, output) = openlifu.sim.run_simulation(arr=arr, \n",
    "        params=params, \n",
    "        delays=delays,\n",
    "        apod= apod,\n",
    "        freq = pulse.frequency,\n",
    "        cycles = np.max([np.round(pulse.duration * pulse.frequency), 20]),\n",
    "        dt=protocol.sim_setup.dt,\n",
    "        t_end=protocol.sim_setup.t_end,\n",
    "        amplitude = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use all of `xarray`s built-in plotting capabilities to plot the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['p_min'].sel(ele=0).plot.imshow()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can examine the output object, which is an `xarray.DataSet` object with 3 data variables: `p_max` (Peak Positive Pressure), `p_min` (Peak Negative Pressure), and `ita` (Time Averaged Intensity). It's attributes also contain the `source` pulse (an `xarray.DataArray`), and `output`, the raw K-Wave output structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `nibabel`, we can export the DataArray to a NIftI file. This requires a little bit of manipulation of the coordinates to extract the origin and affine matrix as NIftI needs them. This should get wrapped into a function in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nb\n",
    "p_min = ds['p_min'].data\n",
    "coords = ds['p_min'].coords\n",
    "affine = np.eye(3) * np.array([float(np.diff(coords[x][:2])) for x in coords])\n",
    "origin = np.array([float(coords[x][0]) for x in coords]).reshape(3,1)\n",
    "affine = np.concatenate([np.concatenate([affine, origin], axis=1),np.array([0,0,0,1]).reshape(1,4)], axis=0)\n",
    "nb.Nifti1Image(p_min, affine).to_filename(\"p_min.nii.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can use some of the intermediate vtk methods to extract Actors from both the array and points objects, and pipe them to a since render:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vtk\n",
    "arr_actor = arr.get_actor(units=\"mm\")\n",
    "renderWindow = vtk.vtkRenderWindow()\n",
    "renderer = vtk.vtkRenderer()\n",
    "renderWindow.AddRenderer(renderer)\n",
    "renderWindowInteractor = vtk.vtkRenderWindowInteractor()\n",
    "renderWindowInteractor.SetRenderWindow(renderWindow)\n",
    "renderer.AddActor(arr_actor)\n",
    "for pti in pts:\n",
    "    pt_actor = pti.get_actor()\n",
    "    renderer.AddActor(pt_actor)\n",
    "renderWindow.Render()\n",
    "renderWindowInteractor.Start()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
